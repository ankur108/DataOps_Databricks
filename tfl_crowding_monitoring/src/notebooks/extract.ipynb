{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81938bea-84e2-43af-879c-2b9c37a2fea6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "019b3b51-11d3-447c-826a-5fa0c5fb0a95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0810fd1-4dd1-4616-ae28-9d254504de20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Initial Variable Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86fa2ac3-17a1-455a-8a5c-33a1e93da866",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Path\n",
    "bronze_dir = \"abfss://bronze@tflopendatalogs.dfs.core.windows.net/Crowding_JSON_Logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "074f1fb7-fd45-4a20-96c5-cfb4c7c10374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Extract Napton Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5417a952-f3c1-4c27-8f84-973a7e48056a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Location of the Volume in Unity Catalog\n",
    "location = '/Volumes/tfl_crowding_analysis_we/default/naptancodes/naptan.csv'\n",
    "\n",
    "# Reading Napton CSV\n",
    "naptan = spark.read.csv(location, header=True, inferSchema=True)\n",
    "\n",
    "# Extracting NaptonID column into list\n",
    "napton_codes = [row['naptanID'] for row in naptan.select('naptanID').collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "137afa2e-1cc3-4be2-a145-16a15856ba75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Extarct Crowding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86d872fa-8101-4539-aa14-82cd8985853e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fetch_and_store_crowding_data(napton_codes, bronze_dir):\n",
    "    \"\"\"\n",
    "    Fetch live crowding data from TFL API for a list of napton codes\n",
    "    and write the relevant fields to Delta Bronze table partitioned by naptonId.\n",
    "    \n",
    "    Args:\n",
    "        napton_codes (list): List of naptan codes to fetch data for.\n",
    "        bronze_dir (str): Path to Bronze Delta table in Databricks.\n",
    "    \"\"\"\n",
    "    for code in napton_codes:\n",
    "\n",
    "        # Debug: Fetching REST API\n",
    "        print(f\"Fetching from REST API for: {code}\")\n",
    "\n",
    "        url = f\"https://api.tfl.gov.uk/crowding/{code}/Live\"\n",
    "\n",
    "        try:\n",
    "            # Send GET request to TFL API\n",
    "            response = requests.get(url)\n",
    "            \n",
    "            # Raise exception if HTTP request returned an error\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse JSON response into Python dict\n",
    "            data = response.json()\n",
    "\n",
    "            # Filter JSON request for Non-Data Request\n",
    "            if not data.get('dataAvailable'):\n",
    "                continue\n",
    "            \n",
    "            # Create Spark DataFrame from JSON response\n",
    "            df = spark.createDataFrame([data])\n",
    "            \n",
    "            # Select only relevant columns for analytics\n",
    "            filter_df = df.select(\"percentageOfBaseline\", \"timeLocal\")\n",
    "            \n",
    "            # Add naptonId column and convert timeLocal to timestamp\n",
    "            final_df = (\n",
    "                filter_df\n",
    "                .withColumn(\"naptonId\", lit(code).cast('string'))\n",
    "                .withColumn(\"percentageOfBaseline\", col('percentageOfBaseline').cast('double'))\n",
    "                .withColumn(\"timeLocal\", col(\"timeLocal\").cast(\"timestamp\"))\n",
    "            )\n",
    "            \n",
    "            # Debug: Print status of writing data\n",
    "            print(f\"Writing Bronze data for naptonId: {code}\")\n",
    "            \n",
    "            # Write data to Bronze Delta table, partitioned by naptonId\n",
    "            final_df.write.partitionBy(\"naptonId\").format(\"delta\").mode(\"append\").save(bronze_dir)\n",
    "\n",
    "            # Write data Bronze schema in UC\n",
    "            final_df.write.mode(\"append\").saveAsTable(\"tfl_crowding_analysis_we.bronze.raw_crowding_logs\")\n",
    "\n",
    "            # Debug: Print status of writing completion\n",
    "            print(f\"Writing Bronze data complted for naptonId: {code}\")\n",
    "        \n",
    "        except requests.exceptions.HTTPError as errh:\n",
    "            print(f\"HTTP Error for {code}: {errh}\")\n",
    "        except requests.exceptions.ConnectionError as errc:\n",
    "            print(f\"Connection Error for {code}: {errc}\")\n",
    "        except requests.exceptions.Timeout as errt:\n",
    "            print(f\"Timeout Error for {code}: {errt}\")\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(f\"Request Exception for {code}: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3a388e9-03ae-4b67-b27f-dec0d5264c34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Call the function with napton codes and Bronze path\n",
    "fetch_and_store_crowding_data(napton_codes, bronze_dir)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "TFL_Crowding_Data_Extract",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
